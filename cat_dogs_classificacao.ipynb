{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8943c1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from matpliotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "803336e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "zip_path = 'dados\\Datasets\\cat_dog_1.zip'\n",
    "zip_file = zipfile.ZipFile(zip_path, 'r')\n",
    "zip_file.extractall('./')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2f3fa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22500,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_path = './cat_dog_1/train'\n",
    "train_files = [os.path.join(train_path, f) for f in os.listdir(train_path)]\n",
    "train_imagens = []\n",
    "classes = [] # 0 - gato, 1 - cachorro\n",
    "\n",
    "for f in train_files:\n",
    "    img = cv2.imread(f, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (150, 150))\n",
    "    img = img.ravel()\n",
    "    train_imagens.append(img)\n",
    "    class_name = os.path.basename(f).split('\\\\')[-1].split('.')[0]\n",
    "\n",
    "    if 'cat' in class_name:\n",
    "        classes.append(0)\n",
    "    else:\n",
    "        classes.append(1)\n",
    "train_imagens = np.asarray(train_imagens)\n",
    "classes = np.asarray(classes)\n",
    "train_imagens.shape, classes.shape\n",
    "\n",
    "total_per_class = np.unique(classes, return_counts=True)\n",
    "total_per_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e1c6c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "train_imagens[0].shape\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(train_imagens)\n",
    "print(X_scaled.min(), X_scaled.max())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b736c2bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2800, 22500), (2800,))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, _, y_train, _ = train_test_split(X_scaled, classes, test_size=0.3, random_state=42, stratify=classes)\n",
    "x_train.shape, y_train.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1caba555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " reshape_1 (Reshape)         (None, 150, 150, 1)       0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 148, 148, 32)      320       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 74, 74, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 72, 72, 64)        18496     \n",
      "                                                                 \n",
      " global_average_pooling2d_1   (None, 64)               0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,041\n",
      "Trainable params: 23,041\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Reshape((150,150,1), input_shape=(22500,)),\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8d9bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "70/70 [==============================] - 9s 22ms/step - loss: 0.6934 - accuracy: 0.4888 - val_loss: 0.6920 - val_accuracy: 0.5732\n",
      "Epoch 2/50\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.6928 - accuracy: 0.5183 - val_loss: 0.6937 - val_accuracy: 0.4911\n",
      "Epoch 3/50\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.6927 - accuracy: 0.5094 - val_loss: 0.6921 - val_accuracy: 0.5054\n",
      "Epoch 4/50\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.6906 - accuracy: 0.5263 - val_loss: 0.6980 - val_accuracy: 0.5071\n",
      "Epoch 5/50\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.6846 - accuracy: 0.5513 - val_loss: 0.6727 - val_accuracy: 0.5839\n",
      "Epoch 6/50\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.6793 - accuracy: 0.5536 - val_loss: 0.6714 - val_accuracy: 0.5786\n",
      "Epoch 7/50\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.6766 - accuracy: 0.5638 - val_loss: 0.6698 - val_accuracy: 0.5571\n",
      "Epoch 8/50\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.6813 - accuracy: 0.5625 - val_loss: 0.6727 - val_accuracy: 0.5732\n",
      "Epoch 9/50\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.6692 - accuracy: 0.5808 - val_loss: 0.6752 - val_accuracy: 0.5339\n",
      "Epoch 10/50\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.6687 - accuracy: 0.5804 - val_loss: 0.6817 - val_accuracy: 0.5321\n",
      "Epoch 11/50\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.6642 - accuracy: 0.5857 - val_loss: 0.6404 - val_accuracy: 0.6446\n",
      "Epoch 12/50\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.6623 - accuracy: 0.5906 - val_loss: 0.6441 - val_accuracy: 0.6232\n",
      "Epoch 13/50\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.6627 - accuracy: 0.6112 - val_loss: 0.6496 - val_accuracy: 0.6000\n",
      "Epoch 14/50\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.6654 - accuracy: 0.5839 - val_loss: 0.6532 - val_accuracy: 0.6089\n",
      "Epoch 15/50\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.6602 - accuracy: 0.5987 - val_loss: 0.6461 - val_accuracy: 0.6107\n",
      "Epoch 16/50\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.6594 - accuracy: 0.6027 - val_loss: 0.6386 - val_accuracy: 0.6268\n",
      "Epoch 17/50\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.6562 - accuracy: 0.6112 - val_loss: 0.6298 - val_accuracy: 0.6446\n",
      "Epoch 18/50\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.6486 - accuracy: 0.6112 - val_loss: 0.6274 - val_accuracy: 0.6482\n",
      "Epoch 19/50\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.6484 - accuracy: 0.6192 - val_loss: 0.6347 - val_accuracy: 0.6196\n",
      "Epoch 20/50\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.6470 - accuracy: 0.6183 - val_loss: 0.6282 - val_accuracy: 0.6375\n",
      "Epoch 21/50\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.6473 - accuracy: 0.6147 - val_loss: 0.6213 - val_accuracy: 0.6464\n",
      "Epoch 22/50\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.6493 - accuracy: 0.6134 - val_loss: 0.6354 - val_accuracy: 0.6250\n",
      "Epoch 23/50\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.6459 - accuracy: 0.6321 - val_loss: 0.6176 - val_accuracy: 0.6714\n",
      "Epoch 24/50\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.6402 - accuracy: 0.6219 - val_loss: 0.6150 - val_accuracy: 0.6679\n",
      "Epoch 25/50\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.6369 - accuracy: 0.6326 - val_loss: 0.6163 - val_accuracy: 0.6429\n",
      "Epoch 26/50\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.6324 - accuracy: 0.6357 - val_loss: 0.6165 - val_accuracy: 0.6464\n",
      "Epoch 27/50\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.6317 - accuracy: 0.6402 - val_loss: 0.6151 - val_accuracy: 0.6482\n",
      "Epoch 28/50\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.6434 - accuracy: 0.6272 - val_loss: 0.6249 - val_accuracy: 0.6357\n",
      "Epoch 29/50\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.6332 - accuracy: 0.6366 - val_loss: 0.6162 - val_accuracy: 0.6679\n",
      "Epoch 30/50\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.6327 - accuracy: 0.6478 - val_loss: 0.6315 - val_accuracy: 0.6304\n",
      "Epoch 31/50\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.6284 - accuracy: 0.6438 - val_loss: 0.6158 - val_accuracy: 0.6536\n",
      "Epoch 32/50\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.6266 - accuracy: 0.6429 - val_loss: 0.6081 - val_accuracy: 0.6607\n",
      "Epoch 33/50\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.6238 - accuracy: 0.6576 - val_loss: 0.6144 - val_accuracy: 0.6500\n",
      "Epoch 34/50\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.6252 - accuracy: 0.6451 - val_loss: 0.6118 - val_accuracy: 0.6446\n",
      "Epoch 35/50\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.6156 - accuracy: 0.6670 - val_loss: 0.6033 - val_accuracy: 0.6500\n",
      "Epoch 36/50\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.6170 - accuracy: 0.6540 - val_loss: 0.6111 - val_accuracy: 0.6589\n",
      "Epoch 37/50\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.6223 - accuracy: 0.6473 - val_loss: 0.6173 - val_accuracy: 0.6464\n",
      "Epoch 38/50\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.6160 - accuracy: 0.6661 - val_loss: 0.5987 - val_accuracy: 0.6714\n",
      "Epoch 39/50\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.6161 - accuracy: 0.6674 - val_loss: 0.6187 - val_accuracy: 0.6482\n",
      "Epoch 40/50\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.6170 - accuracy: 0.6571 - val_loss: 0.6212 - val_accuracy: 0.6482\n",
      "Epoch 41/50\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.6205 - accuracy: 0.6464 - val_loss: 0.6110 - val_accuracy: 0.6589\n",
      "Epoch 42/50\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.6140 - accuracy: 0.6576 - val_loss: 0.6140 - val_accuracy: 0.6589\n",
      "Epoch 43/50\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.6112 - accuracy: 0.6661 - val_loss: 0.6046 - val_accuracy: 0.6571\n",
      "Epoch 44/50\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.6052 - accuracy: 0.6701 - val_loss: 0.6027 - val_accuracy: 0.6589\n",
      "Epoch 45/50\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.6129 - accuracy: 0.6576 - val_loss: 0.6085 - val_accuracy: 0.6536\n",
      "Epoch 46/50\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.6100 - accuracy: 0.6656 - val_loss: 0.6034 - val_accuracy: 0.6554\n",
      "Epoch 47/50\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.6107 - accuracy: 0.6594 - val_loss: 0.6179 - val_accuracy: 0.6554\n",
      "Epoch 48/50\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.6216 - accuracy: 0.6500 - val_loss: 0.6043 - val_accuracy: 0.6500\n",
      "Epoch 49/50\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.6080 - accuracy: 0.6732 - val_loss: 0.6089 - val_accuracy: 0.6536\n",
      "Epoch 50/50\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.5994 - accuracy: 0.6687 - val_loss: 0.5999 - val_accuracy: 0.6643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': [0.6933634877204895,\n",
       "  0.6927931904792786,\n",
       "  0.692713737487793,\n",
       "  0.6905638575553894,\n",
       "  0.6846232414245605,\n",
       "  0.6792738437652588,\n",
       "  0.6766096949577332,\n",
       "  0.6813023090362549,\n",
       "  0.669167697429657,\n",
       "  0.6687007546424866,\n",
       "  0.6642016768455505,\n",
       "  0.6622586250305176,\n",
       "  0.6627013683319092,\n",
       "  0.6653835773468018,\n",
       "  0.6602411270141602,\n",
       "  0.659390389919281,\n",
       "  0.6561726927757263,\n",
       "  0.6485889554023743,\n",
       "  0.6484044194221497,\n",
       "  0.6469930410385132,\n",
       "  0.6472954750061035,\n",
       "  0.6493263244628906,\n",
       "  0.6459370255470276,\n",
       "  0.6402121782302856,\n",
       "  0.636939287185669,\n",
       "  0.6324357986450195,\n",
       "  0.631688117980957,\n",
       "  0.6433829665184021,\n",
       "  0.6332057118415833,\n",
       "  0.632709264755249,\n",
       "  0.6284220218658447,\n",
       "  0.6265689730644226,\n",
       "  0.6238402128219604,\n",
       "  0.625224232673645,\n",
       "  0.6155593395233154,\n",
       "  0.6170191168785095,\n",
       "  0.622340202331543,\n",
       "  0.6160055994987488,\n",
       "  0.6161333322525024,\n",
       "  0.6169820427894592,\n",
       "  0.6205224394798279,\n",
       "  0.6140381097793579,\n",
       "  0.6112383604049683,\n",
       "  0.6052355170249939,\n",
       "  0.6128612160682678,\n",
       "  0.6100237369537354,\n",
       "  0.6106751561164856,\n",
       "  0.6215919852256775,\n",
       "  0.6080486178398132,\n",
       "  0.5994414687156677],\n",
       " 'accuracy': [0.4888392984867096,\n",
       "  0.5183035731315613,\n",
       "  0.5093749761581421,\n",
       "  0.5263392925262451,\n",
       "  0.5513392686843872,\n",
       "  0.5535714030265808,\n",
       "  0.5638392567634583,\n",
       "  0.5625,\n",
       "  0.5808035731315613,\n",
       "  0.5803571343421936,\n",
       "  0.5857142806053162,\n",
       "  0.590624988079071,\n",
       "  0.6111606955528259,\n",
       "  0.5839285850524902,\n",
       "  0.5986607074737549,\n",
       "  0.6026785969734192,\n",
       "  0.6111606955528259,\n",
       "  0.6111606955528259,\n",
       "  0.6191964149475098,\n",
       "  0.6183035969734192,\n",
       "  0.6147321462631226,\n",
       "  0.6133928298950195,\n",
       "  0.6321428418159485,\n",
       "  0.621874988079071,\n",
       "  0.6325892806053162,\n",
       "  0.6357142925262451,\n",
       "  0.6401785612106323,\n",
       "  0.6272321343421936,\n",
       "  0.6366071701049805,\n",
       "  0.6477678418159485,\n",
       "  0.643750011920929,\n",
       "  0.6428571343421936,\n",
       "  0.6575892567634583,\n",
       "  0.6450892686843872,\n",
       "  0.6669642925262451,\n",
       "  0.6540178656578064,\n",
       "  0.6473214030265808,\n",
       "  0.6660714149475098,\n",
       "  0.6674107313156128,\n",
       "  0.6571428775787354,\n",
       "  0.6464285850524902,\n",
       "  0.6575892567634583,\n",
       "  0.6660714149475098,\n",
       "  0.6700893044471741,\n",
       "  0.6575892567634583,\n",
       "  0.6656249761581421,\n",
       "  0.659375011920929,\n",
       "  0.6499999761581421,\n",
       "  0.6732142567634583,\n",
       "  0.668749988079071],\n",
       " 'val_loss': [0.691996693611145,\n",
       "  0.6937155723571777,\n",
       "  0.6920734643936157,\n",
       "  0.6980236172676086,\n",
       "  0.6727167367935181,\n",
       "  0.6713768243789673,\n",
       "  0.6698009967803955,\n",
       "  0.6726948618888855,\n",
       "  0.6752474904060364,\n",
       "  0.681717574596405,\n",
       "  0.6404134631156921,\n",
       "  0.6441108584403992,\n",
       "  0.6496294736862183,\n",
       "  0.6532378792762756,\n",
       "  0.6460853219032288,\n",
       "  0.6385999917984009,\n",
       "  0.6298484802246094,\n",
       "  0.6273586750030518,\n",
       "  0.6346923112869263,\n",
       "  0.6281648874282837,\n",
       "  0.6213396191596985,\n",
       "  0.6353679299354553,\n",
       "  0.6175972819328308,\n",
       "  0.6149555444717407,\n",
       "  0.6162803173065186,\n",
       "  0.6164945363998413,\n",
       "  0.6150653958320618,\n",
       "  0.6248772144317627,\n",
       "  0.616236686706543,\n",
       "  0.6314698457717896,\n",
       "  0.6158202290534973,\n",
       "  0.6081416010856628,\n",
       "  0.6144150495529175,\n",
       "  0.6118468046188354,\n",
       "  0.6032741665840149,\n",
       "  0.6111489534378052,\n",
       "  0.6172809600830078,\n",
       "  0.5987001657485962,\n",
       "  0.6187310218811035,\n",
       "  0.6211759448051453,\n",
       "  0.6109898686408997,\n",
       "  0.6139798760414124,\n",
       "  0.6046133041381836,\n",
       "  0.6027269959449768,\n",
       "  0.608468234539032,\n",
       "  0.6034018397331238,\n",
       "  0.6178681254386902,\n",
       "  0.6042769551277161,\n",
       "  0.6089069247245789,\n",
       "  0.5998600721359253],\n",
       " 'val_accuracy': [0.5732142925262451,\n",
       "  0.4910714328289032,\n",
       "  0.5053571462631226,\n",
       "  0.5071428418159485,\n",
       "  0.5839285850524902,\n",
       "  0.5785714387893677,\n",
       "  0.5571428537368774,\n",
       "  0.5732142925262451,\n",
       "  0.5339285731315613,\n",
       "  0.5321428775787354,\n",
       "  0.6446428298950195,\n",
       "  0.6232143044471741,\n",
       "  0.6000000238418579,\n",
       "  0.6089285612106323,\n",
       "  0.6107142567634583,\n",
       "  0.6267856955528259,\n",
       "  0.6446428298950195,\n",
       "  0.6482142806053162,\n",
       "  0.6196428537368774,\n",
       "  0.637499988079071,\n",
       "  0.6464285850524902,\n",
       "  0.625,\n",
       "  0.6714285612106323,\n",
       "  0.6678571701049805,\n",
       "  0.6428571343421936,\n",
       "  0.6464285850524902,\n",
       "  0.6482142806053162,\n",
       "  0.6357142925262451,\n",
       "  0.6678571701049805,\n",
       "  0.6303571462631226,\n",
       "  0.6535714268684387,\n",
       "  0.6607142686843872,\n",
       "  0.6499999761581421,\n",
       "  0.6446428298950195,\n",
       "  0.6499999761581421,\n",
       "  0.6589285731315613,\n",
       "  0.6464285850524902,\n",
       "  0.6714285612106323,\n",
       "  0.6482142806053162,\n",
       "  0.6482142806053162,\n",
       "  0.6589285731315613,\n",
       "  0.6589285731315613,\n",
       "  0.6571428775787354,\n",
       "  0.6589285731315613,\n",
       "  0.6535714268684387,\n",
       "  0.6553571224212646,\n",
       "  0.6553571224212646,\n",
       "  0.6499999761581421,\n",
       "  0.6535714268684387,\n",
       "  0.6642857193946838]}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55302de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pegar os dados de tests"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
